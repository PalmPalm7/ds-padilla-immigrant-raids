{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38e3f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr4/ugrad/namann/.local/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.16) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import csv \n",
    "import time\n",
    "from gnews import GNews\n",
    "google_news = GNews()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ddd5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n"
     ]
    }
   ],
   "source": [
    "def abb_to_state(abbreviation):\n",
    "    state_dict = {\n",
    "        \"AL\": \"Alabama\",\n",
    "        \"AK\": \"Alaska\",\n",
    "        \"AZ\": \"Arizona\",\n",
    "        \"AR\": \"Arkansas\",\n",
    "        \"CA\": \"California\",\n",
    "        \"CO\": \"Colorado\",\n",
    "        \"CT\": \"Connecticut\",\n",
    "        \"DE\": \"Delaware\",\n",
    "        \"FL\": \"Florida\",\n",
    "        \"GA\": \"Georgia\",\n",
    "        \"HI\": \"Hawaii\",\n",
    "        \"ID\": \"Idaho\",\n",
    "        \"IL\": \"Illinois\",\n",
    "        \"IN\": \"Indiana\",\n",
    "        \"IA\": \"Iowa\",\n",
    "        \"KS\": \"Kansas\",\n",
    "        \"KY\": \"Kentucky\",\n",
    "        \"LA\": \"Louisiana\",\n",
    "        \"ME\": \"Maine\",\n",
    "        \"MD\": \"Maryland\",\n",
    "        \"MA\": \"Massachusetts\",\n",
    "        \"MI\": \"Michigan\",\n",
    "        \"MN\": \"Minnesota\",\n",
    "        \"MS\": \"Mississippi\",\n",
    "        \"MO\": \"Missouri\",\n",
    "        \"MT\": \"Montana\",\n",
    "        \"NE\": \"Nebraska\",\n",
    "        \"NV\": \"Nevada\",\n",
    "        \"NH\": \"New Hampshire\",\n",
    "        \"NJ\": \"New Jersey\",\n",
    "        \"NM\": \"New Mexico\",\n",
    "        \"NY\": \"New York\",\n",
    "        \"NC\": \"North Carolina\",\n",
    "        \"ND\": \"North Dakota\",\n",
    "        \"OH\": \"Ohio\",\n",
    "        \"OK\": \"Oklahoma\",\n",
    "        \"OR\": \"Oregon\",\n",
    "        \"PA\": \"Pennsylvania\",\n",
    "        \"RI\": \"Rhode Island\",\n",
    "        \"SC\": \"South Carolina\",\n",
    "        \"SD\": \"South Dakota\",\n",
    "        \"TN\": \"Tennessee\",\n",
    "        \"TX\": \"Texas\",\n",
    "        \"UT\": \"Utah\",\n",
    "        \"VT\": \"Vermont\",\n",
    "        \"VA\": \"Virginia\",\n",
    "        \"WA\": \"Washington\",\n",
    "        \"WV\": \"West Virginia\",\n",
    "        \"WI\": \"Wisconsin\",\n",
    "        \"WY\": \"Wyoming\",\n",
    "    }\n",
    "    \n",
    "    return state_dict.get(abbreviation.upper(), \"Abbreviation not found. Please enter a valid state abbreviation.\")\n",
    "\n",
    "\n",
    "print(abb_to_state(\"NY\"))  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646e3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Datasets/abnormal_arrest_dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75391e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['arrestdate'] = pd.to_datetime(df['arrestdate'])\n",
    "for x in range(len(df['ST'])):\n",
    "    df['ST'][x] =  abb_to_state(df['ST'][x])\n",
    "    df['date_start'] = df['arrestdate'] - pd.Timedelta(days=2)\n",
    "    df['date_end'] = df['arrestdate'] + pd.Timedelta(days=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c154821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raid (y=1, n=0)</th>\n",
       "      <th>Source</th>\n",
       "      <th>Source2</th>\n",
       "      <th>Source3</th>\n",
       "      <th>arrestdate</th>\n",
       "      <th>date_start</th>\n",
       "      <th>date_end</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>ST</th>\n",
       "      <th>arrests</th>\n",
       "      <th>...</th>\n",
       "      <th>city2</th>\n",
       "      <th>city3</th>\n",
       "      <th>location (qualitatively)</th>\n",
       "      <th>target  (location targeted: 1=restaurant 2=mobile home park 3=courthouse 4=jail 5= county 6=city/town, 7= store/establishment 8=state 9=hotel 10=church 11=private home 12=agricultural business 13= hospital 14= spa/salon 15= money remitters 16= national park)</th>\n",
       "      <th>previousconviction (percent)</th>\n",
       "      <th>female</th>\n",
       "      <th>nationality</th>\n",
       "      <th>StateCountyFIPS</th>\n",
       "      <th>FIPSState</th>\n",
       "      <th>FIPSCounty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-02-16</td>\n",
       "      <td>2018-02-14</td>\n",
       "      <td>2018-03-02</td>\n",
       "      <td>Rusk</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48401</td>\n",
       "      <td>48</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>Sandusky</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39143</td>\n",
       "      <td>39</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1073</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-15</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>2016-08-29</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40109</td>\n",
       "      <td>40</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>2017-02-06</td>\n",
       "      <td>2017-02-22</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40109</td>\n",
       "      <td>40</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>2016-09-25</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-05</td>\n",
       "      <td>2016-10-03</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>2016-10-10</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>2016-10-17</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>2016-11-24</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1097</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Raid (y=1, n=0)  Source  Source2  Source3 arrestdate date_start  \\\n",
       "0                NaN     NaN      NaN      NaN 2018-02-16 2018-02-14   \n",
       "1                NaN     NaN      NaN      NaN 2015-03-03 2015-03-01   \n",
       "2                NaN     NaN      NaN      NaN 2018-03-08 2018-03-06   \n",
       "3                NaN     NaN      NaN      NaN 2016-08-15 2016-08-13   \n",
       "4                NaN     NaN      NaN      NaN 2017-02-08 2017-02-06   \n",
       "..               ...     ...      ...      ...        ...        ...   \n",
       "757              NaN     NaN      NaN      NaN 2016-09-27 2016-09-25   \n",
       "758              NaN     NaN      NaN      NaN 2016-10-05 2016-10-03   \n",
       "759              NaN     NaN      NaN      NaN 2016-10-12 2016-10-10   \n",
       "760              NaN     NaN      NaN      NaN 2016-10-19 2016-10-17   \n",
       "761              NaN     NaN      NaN      NaN 2016-11-10 2016-11-08   \n",
       "\n",
       "      date_end CountyName        ST  arrests  ...  city2  city3  \\\n",
       "0   2018-03-02       Rusk     Texas      NaN  ...    NaN    NaN   \n",
       "1   2015-03-17   Sandusky      Ohio      NaN  ...    NaN    NaN   \n",
       "2   2018-03-22  Jefferson   Alabama      NaN  ...    NaN    NaN   \n",
       "3   2016-08-29   Oklahoma  Oklahoma      NaN  ...    NaN    NaN   \n",
       "4   2017-02-22   Oklahoma  Oklahoma      NaN  ...    NaN    NaN   \n",
       "..         ...        ...       ...      ...  ...    ...    ...   \n",
       "757 2016-10-11     Mobile   Alabama      NaN  ...    NaN    NaN   \n",
       "758 2016-10-19     Mobile   Alabama      NaN  ...    NaN    NaN   \n",
       "759 2016-10-26     Mobile   Alabama      NaN  ...    NaN    NaN   \n",
       "760 2016-11-02     Mobile   Alabama      NaN  ...    NaN    NaN   \n",
       "761 2016-11-24     Mobile   Alabama      NaN  ...    NaN    NaN   \n",
       "\n",
       "     location (qualitatively)  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "..                        ...   \n",
       "757                       NaN   \n",
       "758                       NaN   \n",
       "759                       NaN   \n",
       "760                       NaN   \n",
       "761                       NaN   \n",
       "\n",
       "     target  (location targeted: 1=restaurant 2=mobile home park 3=courthouse 4=jail 5= county 6=city/town, 7= store/establishment 8=state 9=hotel 10=church 11=private home 12=agricultural business 13= hospital 14= spa/salon 15= money remitters 16= national park)  \\\n",
       "0                                                  NaN                                                                                                                                                                                                                    \n",
       "1                                                  NaN                                                                                                                                                                                                                    \n",
       "2                                                  NaN                                                                                                                                                                                                                    \n",
       "3                                                  NaN                                                                                                                                                                                                                    \n",
       "4                                                  NaN                                                                                                                                                                                                                    \n",
       "..                                                 ...                                                                                                                                                                                                                    \n",
       "757                                                NaN                                                                                                                                                                                                                    \n",
       "758                                                NaN                                                                                                                                                                                                                    \n",
       "759                                                NaN                                                                                                                                                                                                                    \n",
       "760                                                NaN                                                                                                                                                                                                                    \n",
       "761                                                NaN                                                                                                                                                                                                                    \n",
       "\n",
       "     previousconviction (percent)  female  nationality  StateCountyFIPS  \\\n",
       "0                             NaN     NaN          NaN            48401   \n",
       "1                             NaN     NaN          NaN            39143   \n",
       "2                             NaN     NaN          NaN             1073   \n",
       "3                             NaN     NaN          NaN            40109   \n",
       "4                             NaN     NaN          NaN            40109   \n",
       "..                            ...     ...          ...              ...   \n",
       "757                           NaN     NaN          NaN             1097   \n",
       "758                           NaN     NaN          NaN             1097   \n",
       "759                           NaN     NaN          NaN             1097   \n",
       "760                           NaN     NaN          NaN             1097   \n",
       "761                           NaN     NaN          NaN             1097   \n",
       "\n",
       "     FIPSState  FIPSCounty  \n",
       "0           48         401  \n",
       "1           39         143  \n",
       "2            1          73  \n",
       "3           40         109  \n",
       "4           40         109  \n",
       "..         ...         ...  \n",
       "757          1          97  \n",
       "758          1          97  \n",
       "759          1          97  \n",
       "760          1          97  \n",
       "761          1          97  \n",
       "\n",
       "[762 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Datasets/Intermediate_output.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['County', 'State', 'Arrest_Date', 'Start_Date_Param', 'End_Date_Param', 'Article_Title', 'Article_Link', 'Article_Date', 'Query Term'])\n",
    "        \n",
    "    #Immigration Raid\n",
    "    for x in tqdm(range(len(df['ST']))):\n",
    "        #print(f\"looking at {df['CountyName'][x]}{df['ST'][x]} \")\n",
    "        google_news.start_date = (df['date_start'].dt.year[x], df['date_start'].dt.month[x], df['date_start'].dt.day[x]) # Search from 1st Jan 2020\n",
    "        google_news.end_date = (df['date_end'].dt.year[x], df['date_end'].dt.month[x], df['date_end'].dt.day[x])\n",
    "        links = google_news.get_news(f\"Immigration raid {df['CountyName'][x]} county {df['ST'][x]}\")\n",
    "\n",
    "        if len(links) != 0:\n",
    "            for link in links:\n",
    "                writer.writerow([df['CountyName'][x], df['ST'][x], df['arrestdate'][x], df['date_start'][x], \n",
    "                                    df['date_end'][x], link['title'], link['url'], link['published date'], 'Immigration Raid'])\n",
    "       \n",
    "       # time.sleep(1)\n",
    "    #Raid arrest\n",
    "    for x in tqdm(range(len(df['ST']))):\n",
    "        #print(f\"looking at {df['CountyName'][x]}{df['ST'][x]} \")\n",
    "        google_news.start_date = (df['date_start'].dt.year[x], df['date_start'].dt.month[x], df['date_start'].dt.day[x]) # Search from 1st Jan 2020\n",
    "        google_news.end_date = (df['date_end'].dt.year[x], df['date_end'].dt.month[x], df['date_end'].dt.day[x])\n",
    "        links = google_news.get_news(f\"Raid arrest {df['CountyName'][x]} county {df['ST'][x]}\")\n",
    "\n",
    "        if len(links) != 0:\n",
    "            for link in links:\n",
    "                writer.writerow([df['CountyName'][x], df['ST'][x], df['arrestdate'][x], df['date_start'][x], \n",
    "                                    df['date_end'][x], link['title'], link['url'], link['published date'], 'Raid Arrest'])\n",
    "      \n",
    "        time.sleep(1)\n",
    "    #Ice Raid\n",
    "    for x in tqdm(range(len(df['ST']))):\n",
    "        #print(f\"looking at {df['CountyName'][x]}{df['ST'][x]} \")\n",
    "        google_news.start_date = (df['date_start'].dt.year[x], df['date_start'].dt.month[x], df['date_start'].dt.day[x]) # Search from 1st Jan 2020\n",
    "        google_news.end_date = (df['date_end'].dt.year[x], df['date_end'].dt.month[x], df['date_end'].dt.day[x])\n",
    "        links = google_news.get_news(f\"ICE raid {df['CountyName'][x]} county {df['ST'][x]}\")\n",
    "\n",
    "        if len(links) != 0:\n",
    "            for link in links:\n",
    "                writer.writerow([df['CountyName'][x], df['ST'][x], df['arrestdate'][x], df['date_start'][x], \n",
    "                                    df['date_end'][x], link['title'], link['url'], link['published date'], 'ICE raid'])\n",
    "       \n",
    "        time.sleep(1)\n",
    "            \n",
    "    #Immigration Raid NC\n",
    "    for x in tqdm(range(len(df['ST']))):\n",
    "        #print(f\"looking at {df['CountyName'][x]}{df['ST'][x]} \")\n",
    "        google_news.start_date = (df['date_start'].dt.year[x], df['date_start'].dt.month[x], df['date_start'].dt.day[x]) # Search from 1st Jan 2020\n",
    "        google_news.end_date = (df['date_end'].dt.year[x], df['date_end'].dt.month[x], df['date_end'].dt.day[x])\n",
    "        links = google_news.get_news(f\"Immigration raid {df['CountyName'][x]}, {df['ST'][x]}\")\n",
    "\n",
    "        if len(links) != 0:\n",
    "            for link in links:\n",
    "                writer.writerow([df['CountyName'][x], df['ST'][x], df['arrestdate'][x], df['date_start'][x], \n",
    "                                    df['date_end'][x], link['title'], link['url'], link['published date'], 'Immigration Raid NC'])\n",
    "   \n",
    "        time.sleep(1)\n",
    "    #Raid arrest NC\n",
    "    for x in tqdm(range(len(df['ST']))):\n",
    "        #print(f\"looking at {df['CountyName'][x]}{df['ST'][x]} \")\n",
    "        google_news.start_date = (df['date_start'].dt.year[x], df['date_start'].dt.month[x], df['date_start'].dt.day[x]) # Search from 1st Jan 2020\n",
    "        google_news.end_date = (df['date_end'].dt.year[x], df['date_end'].dt.month[x], df['date_end'].dt.day[x])\n",
    "        links = google_news.get_news(f\"Raid arrest {df['CountyName'][x]}, {df['ST'][x]}\")\n",
    "\n",
    "        if len(links) != 0:\n",
    "            for link in links:\n",
    "                writer.writerow([df['CountyName'][x], df['ST'][x], df['arrestdate'][x], df['date_start'][x], \n",
    "                                    df['date_end'][x], link['title'], link['url'], link['published date'], 'Raid Arrest NC'])\n",
    "        \n",
    "        time.sleep(1)\n",
    "    #Ice Raid NC\n",
    "    for x in tqdm(range(len(df['ST']))):\n",
    "        #print(f\"looking at {df['CountyName'][x]}{df['ST'][x]} \")\n",
    "        google_news.start_date = (df['date_start'].dt.year[x], df['date_start'].dt.month[x], df['date_start'].dt.day[x]) # Search from 1st Jan 2020\n",
    "        google_news.end_date = (df['date_end'].dt.year[x], df['date_end'].dt.month[x], df['date_end'].dt.day[x])\n",
    "        links = google_news.get_news(f\"ICE raid {df['CountyName'][x]}, {df['ST'][x]}\")\n",
    "\n",
    "        if len(links) != 0:\n",
    "            for link in links:\n",
    "                writer.writerow([df['CountyName'][x], df['ST'][x], df['arrestdate'][x], df['date_start'][x], \n",
    "                                    df['date_end'][x], link['title'], link['url'], link['published date'], 'ICE raid NC'])\n",
    "        \n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Intermediate_output.csv')\n",
    "grouped = df.groupby('combined')['Query Term'].apply(lambda x: ', '.join(x.unique())).reset_index()\n",
    "\n",
    "df_merged = df.merge(grouped, on='combined', how='left')\n",
    "\n",
    "df_cleaned = df_merged.drop_duplicates(subset='combined')\n",
    "\n",
    "df_final = df_cleaned.drop(columns=['combined', 'Query Term_x'])\n",
    "df_final = df_final.rename(columns={'Query Term_y': 'Query_Term'})\n",
    "df_final.to_csv('Intermediate_csv.csv')\n",
    "os.remove('Intermediate_output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
