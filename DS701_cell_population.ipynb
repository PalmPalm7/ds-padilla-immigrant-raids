{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken manually from Raids_Data\n",
    "#from rows 28, 63, 124, 126, 127, 201, 202, 208, 209, 267, 452, 463.\n",
    "\n",
    "# the article given in the row 63 doesn't contain the information of arrest_date and end_date\n",
    "# so, I changed from (2/9/16, 2/23/16) to (None, None)\n",
    "\n",
    "# test_enddate_labels row124 value changed from \"2/22/16\" to \"2/23/16\", after reading the article\n",
    "# look at the line 'The indictment was returned under seal on Feb. 9, 2016, and unsealed yesterday after the nine defendants were arrested.'\n",
    "# yesterday refers to Feb 23th\n",
    "\n",
    "# the article given in the row 126 doesn't contain the information of arrest_date and end_date\n",
    "# so, I changed from (2/23/16, 2/23/16) to (None, None)\n",
    "\n",
    "# the article given in the row 127 doesn't contain the information of arrest_date and end_date\n",
    "# so, I changed from (2/26/16, 2/26/16) to (None, None)\n",
    "\n",
    "# the article given in the row 201 contains the date information, but the article is Spanish.\n",
    "\n",
    "# It is hard to find the dates from the article given in the row 202 \n",
    "\n",
    "# It is hard to find the dates from the article given in the row 208 \n",
    "\n",
    "# It is hard to find the dates from the article given in the row 267\n",
    "\n",
    "# It is hard to find the dates from the article given in the row 463\n",
    "\n",
    "\n",
    "test_arrestdate_labels=[\"05/18/15\", \"None\",\"02/09/16\",\"None\",\"None\",\"06/09/16\",\"07/17/16\",\"08/08/16\",\"09/06/16\",\"03/07/17\",\"04/09/18\", \"04/16/18\"]\n",
    "test_enddate_labels=[\"06/13/15\",\"None\",\"02/23/16\",\"None\",\"None\",\"06/16/16\",\"07/20/16\",\"08/08/16\",\"09/06/16\",\"03/10/17\",\"04/24/18\",\"04/20/18\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Wisconsin men were arrested by Immigration and Customs Enforcement\n",
      "\n",
      "Posted: Jun 17, 2015 3:04 PM CST\n",
      "\n",
      "Immigration and Customs Enforcement arrested 280 convicted criminal aliens in six Midwestern states during a month long initiative which ended Saturday.\n",
      "\n",
      "ICE officers arrested 34 males in Wisconsin during the initiative. All are Mexican nationals, except for one Ecuadorian national who was also arrested. Arrests occurred in the following Wisconsin communities: Arcadia, Deerfield, Franksville, Gillette, Green Bay, Hilbert, Humbird, Janesville, Kenosha, Kewaunee, Madison, Manitowoc, Milwaukee, Princeton, Racine, and Wautoma.\n",
      "\n",
      "A previously deported 31-year-old Mexican national with a prior burglary conviction was arrested in Madison. He illegally re-entered the United States after being deported in 2012. He remains in ICE custody pending deportation.\n",
      "\n",
      "In Milwaukee, a previously deported 28-year-old Mexican national with multiple prior convictions for possessing a weapon, possessing cocaine, possessing stolen property, and larceny was arrested. He illegally re-entered the United States after being deported in 2009. He was arrested May 21 in Milwaukee and is in local custody pending drug charges. Once those charges are resolved he will be turned over to ICE for deportation.\n",
      "\n",
      "The 272 men and eight women arrested are from 22 countries.\n",
      "\n",
      "This enforcement surge began May 18 and concluded June 13. It was the latest effort by ICE to prioritize the arrest and removal of convicted criminal aliens. The arrests were made in the following six states: Illinois, Indiana, Wisconsin, Kentucky, Kansas and Missouri.\n",
      "\n",
      "All 280 individuals arrested have been convicted of crimes in the United States and fall within ICE's enforcement priorities for deportation. Overall, their convictions include: aggravated robbery, armed robbery, drug possession, burglary, aggravated drunken driving, illegal possessing a weapon by a felon, battery, hit-and-run, and drug trafficking.\n",
      "\n",
      "“Our dedicated officers strive to make our communities safer by arresting convicted criminal aliens and removing them from the United States,\\\" said Ricardo Wong, field officer director for ERO Chicago. \\\"By focusing our resources on the most egregious offenders, we ensure the very best use of our resources while immediately improving public safety.”\n",
      "\n",
      "In fiscal year 2014, ICE conducted 315,943 removals nationwide. Eighty-five percent of individuals removed from the interior of the United States had previously been convicted of a criminal offense.\n"
     ]
    }
   ],
   "source": [
    "info0=\"\"\n",
    "\n",
    "with open(directory+\"row28_article_text.txt\", \"r\") as row28:\n",
    "    for line in row28:\n",
    "        info0 +=line\n",
    "        \n",
    "print(info0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_arrestdate0=\"\"\"Your task is to analyze the given context and determine if the starting date of the U.S. ICE (Immigration and Customs Enforcement) operation is mentioned.\n",
    "\n",
    "Key details:\n",
    "\n",
    "The context is a web article about the operation.\n",
    "The starting date must include the day, month, and year to be considered \"mentioned.\"\n",
    "The date might be explicitly stated or inferred through time references (e.g., \"yesterday,\" \"last week\") combined with the article's publication date (if available).\n",
    "\n",
    "Response instructions:\n",
    "\n",
    "Respond True if the starting date is mentioned and all three components (day, month, year) can be identified directly or inferred.\n",
    "Respond False if any component (day, month, year) is missing or cannot be determined.\n",
    "Do not guess or make up information.\n",
    "Context: ### {context} ###\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to analyze the given context and determine if the starting date of the U.S. ICE (Immigration and Customs Enforcement) operation is mentioned.\n",
      "\n",
      "Key details:\n",
      "\n",
      "The context is a web article about the operation.\n",
      "The starting date must include the day, month, and year to be considered \"mentioned.\"\n",
      "The date might be explicitly stated or inferred through time references (e.g., \"yesterday,\" \"last week\") combined with the article's publication date (if available).\n",
      "\n",
      "Response instructions:\n",
      "\n",
      "Respond True if the starting date is mentioned and all three components (day, month, year) can be identified directly or inferred.\n",
      "Respond False if any component (day, month, year) is missing or cannot be determined.\n",
      "Do not guess or make up information.\n",
      "Context: ### {context} ###\n"
     ]
    }
   ],
   "source": [
    "print(prompt_arrestdate0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_arrestdate1=\"\"\"Your task is to analyze the given context and determine the starting date of the U.S. ICE (Immigration and Customs Enforcement) operation.\n",
    "\n",
    "Key details:\n",
    "\n",
    "The context is a web article about the operation.\n",
    "The starting date might be stated explicitly (e.g., a specific date) or implicitly through time references (e.g., \"yesterday,\" \"last week\").\n",
    "Use the article's publication date (if available) to infer the starting date based on time references.\n",
    "Focus only on identifying the operation's starting date. Ignore other dates mentioned in the article.\n",
    "\n",
    "Response format:\n",
    "\n",
    "Only provide the date in the format mm/dd/yy (e.g., 04/15/23).\n",
    "If the starting date cannot be determined, do not guess or infer.\n",
    "Context: ### {context} ###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to analyze the given context and determine the starting date of the U.S. ICE (Immigration and Customs Enforcement) operation.\n",
      "\n",
      "Key details:\n",
      "\n",
      "The context is a web article about the operation.\n",
      "The starting date might be stated explicitly (e.g., a specific date) or implicitly through time references (e.g., \"yesterday,\" \"last week\").\n",
      "Use the article's publication date (if available) to infer the starting date based on time references.\n",
      "Focus only on identifying the operation's starting date. Ignore other dates mentioned in the article.\n",
      "\n",
      "Response format:\n",
      "\n",
      "Only provide the date in the format mm/dd/yy (e.g., 04/15/23).\n",
      "If the starting date cannot be determined, do not guess or infer.\n",
      "Context: ### {context} ###\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_arrestdate1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_format(response: str)->bool:\n",
    "    \n",
    "    print(f\"RESPONSE IS {response}\")\n",
    "\n",
    "    if response[0] not in \"01\":\n",
    "        return False\n",
    "    if response[1] not in \"0123456789\":\n",
    "        return False\n",
    "    if response[2]!=\"/\":\n",
    "        return False\n",
    "    if response[3] not in \"0123\":\n",
    "        return False\n",
    "    if response[4] not in \"0123456789\":\n",
    "        return False    \n",
    "    if response[5]!=\"/\":\n",
    "        return False\n",
    "    if response[6]!=\"1\":\n",
    "        return False \n",
    "    if response[7] not in \"45678\":\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "    \n",
    "def model1_arrestdate(model_name: str, info: str, info_name: str, prompt0: str, prompt1: str):\n",
    "    \n",
    "    cost=0.0\n",
    "    \n",
    "    PROMPT0 = PromptTemplate(template=prompt0, input_variables=[\"context\"])\n",
    "    \n",
    "    with get_openai_callback() as cb0:\n",
    "        llm = LLMChain(\n",
    "            llm = ChatOpenAI(openai_api_key=api_key,\n",
    "                     temperature=0.01, model=model_name), prompt=PROMPT0)\n",
    "    \n",
    "        response0 = llm.predict(context=info)\n",
    "    \n",
    "        cost +=cb0.total_cost\n",
    "    \n",
    "    if response0!=\"True\" and response0!=\"False\":\n",
    "        print(\"ERROR: Got an unexpected response when looking if the answer is present in the article\")\n",
    "        print(f\"UNEXPECTED RESPONSE: {response0}\")\n",
    "        print(\"The article is:\")\n",
    "        print(info)\n",
    "        print(f\"The article name is {info_name}\")\n",
    "        return None, cost\n",
    "    \n",
    "    if response0==\"False\":\n",
    "        print(\"The information you are asking cannot be found only by looking at the given article\")\n",
    "        print(\"Provide more articles!\")\n",
    "        return None, cost\n",
    "    \n",
    "    PROMPT1 = PromptTemplate(template=prompt1, input_variables=[\"context\"])\n",
    "    \n",
    "    with get_openai_callback() as cb1:\n",
    "        llm = LLMChain(\n",
    "            llm = ChatOpenAI(openai_api_key=api_key,\n",
    "                     temperature=0.01, model=\"gpt-4o\"), prompt=PROMPT1)\n",
    "        \n",
    "        \n",
    "        response1 = llm.predict(context=info)\n",
    "    \n",
    "        cost +=cb1.total_cost\n",
    "    \n",
    "    if not (check_format(response1)):\n",
    "        print(\"The date is found but is not given in the mm/dd/yy format\")\n",
    "        print(f\"Instead got: {response1}\")\n",
    "        return None, cost\n",
    "    \n",
    "    print(f\"FOUND: {response1}\")\n",
    "    \n",
    "    \n",
    "    return response1, cost\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipline1_arrestdate(directory, files, model_name):\n",
    "    \n",
    "    labels=[]\n",
    "    cost=0.0\n",
    "    \n",
    "    for file in files:\n",
    "        info=\"\"\n",
    "        with open(directory+file,\"r\") as f:\n",
    "            \n",
    "            for line in f:\n",
    "                \n",
    "                info += line\n",
    "                \n",
    "                \n",
    "        response,c= model1_arrestdate(model_name, info, file, prompt_arrestdate0, prompt_arrestdate1)\n",
    "        \n",
    "        cost += c\n",
    "        \n",
    "        labels+=[\"None\" if response==None else response]\n",
    "        \n",
    "        \n",
    "    return labels, cost\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE IS 05/18/15\n",
      "FOUND: 05/18/15\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "RESPONSE IS 07/17/16\n",
      "FOUND: 07/17/16\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n"
     ]
    }
   ],
   "source": [
    "directory=\"/Users/canerozer/Desktop/BU/FALL2024/DS701/DS701_Proje/question_answering_experiement/\"\n",
    "test_files=[\"row28_article_text.txt\",\"row63_article_text.txt\",\"row124_article_text.txt\",\"row126_article_text.txt\",\"row127_article_text.txt\",\"row201_article_text.txt\",\"row202_article_text.txt\",\"row208_article_text.txt\",\"row209_article_text.txt\",\"row267_article_text.txt\",\"row452_article_text.txt\",\"row463_article_text.txt\"]\n",
    "\n",
    "labels, cost= pipline1_arrestdate(directory, test_files, \"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05/18/15', 'None', 'None', 'None', 'None', 'None', '07/17/16', 'None', 'None', 'None', 'None', 'None']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gpt-4o with model1 is 0.4166666666666667\n",
      "Cost for gpt-4o with model1 is 0.0353525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(test_arrestdate_labels, labels)\n",
    "\n",
    "print(f\"Accuracy for gpt-4o with model1 is {accuracy}\")\n",
    "print(f\"Cost for gpt-4o with model1 is {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05/18/15',\n",
       " 'None',\n",
       " '02/09/16',\n",
       " 'None',\n",
       " 'None',\n",
       " '06/09/16',\n",
       " '07/17/16',\n",
       " '08/08/16',\n",
       " '09/06/16',\n",
       " '03/07/17',\n",
       " '04/09/18',\n",
       " '04/16/18']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arrestdate_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE IS 05/18/15\n",
      "FOUND: 05/18/15\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "RESPONSE IS 02/01/16\n",
      "FOUND: 02/01/16\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "RESPONSE IS 05/09/23\n",
      "The date is found but is not given in the mm/dd/yy format\n",
      "Instead got: 05/09/23\n",
      "RESPONSE IS 07/17/16\n",
      "FOUND: 07/17/16\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n"
     ]
    }
   ],
   "source": [
    "labels1, cost1= pipline1_arrestdate(directory, test_files, \"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05/18/15',\n",
       " 'None',\n",
       " 'None',\n",
       " '02/01/16',\n",
       " 'None',\n",
       " 'None',\n",
       " '07/17/16',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gpt-4o-mini with model1 is 0.3333333333333333\n",
      "Cost for gpt-4o-mini with model1 is 0.01048365\n"
     ]
    }
   ],
   "source": [
    "accuracy1 = accuracy_score(test_arrestdate_labels, labels1)\n",
    "\n",
    "print(f\"Accuracy for gpt-4o-mini with model1 is {accuracy1}\")\n",
    "print(f\"Cost for gpt-4o-mini with model1 is {cost1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE IS 05/18/15\n",
      "FOUND: 05/18/15\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "RESPONSE IS 03/03/16\n",
      "FOUND: 03/03/16\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "RESPONSE IS 09/06/16\n",
      "FOUND: 09/06/16\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n"
     ]
    }
   ],
   "source": [
    "labels2, cost2= pipline1_arrestdate(directory, test_files, \"gpt-4-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['05/18/15',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '03/03/16',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " '09/06/16',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gpt-4-turbo with model1 is 0.3333333333333333\n",
      "Cost for gpt-4-turbo with model1 is 0.13380999999999998\n"
     ]
    }
   ],
   "source": [
    "accuracy2 = accuracy_score(test_arrestdate_labels, labels2)\n",
    "\n",
    "print(f\"Accuracy for gpt-4-turbo with model1 is {accuracy2}\")\n",
    "print(f\"Cost for gpt-4-turbo with model1 is {cost2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running with the Scraped text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/tz2yk7vs7yx8cp4kyxh06s2r0000gn/T/ipykernel_74524/1799429007.py:32: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE IS 05/18/15\n",
      "FOUND: 05/18/15\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "RESPONSE IS 07/17/16\n",
      "FOUND: 07/17/16\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n",
      "The information you are asking cannot be found only by looking at the given article\n",
      "Provide more articles!\n"
     ]
    }
   ],
   "source": [
    "pred_directory=\"/Users/canerozer/Desktop/BU/FALL2024/DS701/DS701_Proje/text_extraction_experiment/\"\n",
    "pred_files=[\"pred_row28_article_text.txt\",\"pred_row63_article_text.txt\",\"pred_row124_article_text.txt\",\"pred_row126_article_text.txt\",\"pred_row127_article_text.txt\",\"pred_row201_article_text.txt\",\"pred_row202_article_text.txt\",\"pred_row208_article_text.txt\",\"pred_row209_article_text.txt\",\"pred_row267_article_text.txt\",\"pred_row452_article_text.txt\",\"pred_row463_article_text.txt\"]\n",
    "\n",
    "labels, cost= pipline1_arrestdate(pred_directory, pred_files, \"gpt-4o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['05/18/15', 'None', 'None', 'None', 'None', 'None', '07/17/16', 'None', 'None', 'None', 'None', 'None']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gpt-4o with model1 is 0.4166666666666667\n",
      "Cost for gpt-4o with model1 is 0.025485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(test_arrestdate_labels, labels)\n",
    "\n",
    "print(f\"Accuracy for gpt-4o with model1 is {accuracy}\")\n",
    "print(f\"Cost for gpt-4o with model1 is {cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
